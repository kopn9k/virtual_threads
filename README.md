# Virtual Threads vs Platform Threads in Java 21 (Tomcat Context)

Java 21 (with OpenJDK’s Project Loom) introduced **virtual threads** as a lightweight alternative to traditional **platform threads**. This has significant implications for a Tomcat server’s concurrency. Below, we explore JVM-imposed limits on thread counts, Tomcat’s capacity with virtual threads, the practical limits with platform threads, and best practices when switching Tomcat to virtual threads.

## JVM Thread Limits: Virtual Threads vs Platform Threads

**Platform threads** (the traditional Java threads) are thin wrappers around OS threads ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=A%20platform%20thread%20is%20implemented,the%20number%20of%20OS%20threads)). Each platform thread directly consumes an OS thread for its entire lifetime ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=A%20platform%20thread%20is%20implemented,the%20number%20of%20OS%20threads)). There is no hard-coded JVM limit on the number of platform threads; the limit is set by OS resources and memory. In practice, **memory is the primary constraint** – each OS thread requires a large native stack (often around 1 MB or more by default) and OS kernel structures. For example, a Linux kernel might need on the order of *2 MB* of memory per thread ([A primer on Java 21 virtual threads with examples | TheServerSide](https://www.theserverside.com/tip/A-primer-on-Java-21-virtual-threads-with-examples#:~:text=The%20more%20common%20constraint%20on,that%20has%20limited%20memory%20allocation)). This means creating on the order of one million OS threads would consume ~2 **TB** of memory, which is usually infeasible ([A primer on Java 21 virtual threads with examples | TheServerSide](https://www.theserverside.com/tip/A-primer-on-Java-21-virtual-threads-with-examples#:~:text=The%20more%20common%20constraint%20on,that%20has%20limited%20memory%20allocation)). Moreover, operating systems impose limits (configurable) on how many threads a process or user can create. Exceeding these limits can cause failures (as seen in an AWS incident where a service **“ran out of operating system threads”** due to hitting an OS thread count limit) ([A primer on Java 21 virtual threads with examples | TheServerSide](https://www.theserverside.com/tip/A-primer-on-Java-21-virtual-threads-with-examples#:~:text=,end%20clusters)). In summary, platform threads are a limited resource ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=Platform%20threads%20typically%20have%20a,may%20be%20a%20limited%20resource)) – typically in the low thousands at most – constrained by **heap size, native memory for stacks, and OS thread quotas**. You can tune platform thread usage by adjusting the Java stack size (`-Xss`) to reduce per-thread memory, or by increasing OS limits (e.g. ulimit for max user processes), but the fundamental scaling is limited.

**Virtual threads**, by contrast, are *user-mode* threads managed by the JVM, not tied 1:1 to OS threads ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=Like%20a%20platform%20thread%2C%20a,operations%20for%20other%20virtual%20threads)). The JVM schedules many virtual threads on a small pool of OS threads (this is an M:N scheduling model). **There is no fixed hard limit** on the number of virtual threads the JVM can create – a single JVM instance can support **millions of virtual threads** so long as you have sufficient memory ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=Unlike%20platform%20threads%2C%20virtual%20threads,support%20millions%20of%20virtual%20threads)). Each virtual thread’s call stack is stored in the Java heap as lightweight **stack chunks** that expand and shrink on demand ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=Memory%20use%20and%20interaction%20with,garbage%20collection)). This makes the per-thread memory overhead much smaller than a platform thread’s fixed OS stack. By design, a virtual thread that performs blocking I/O will *automatically yield* its OS thread, allowing that OS thread (carrier) to run other virtual threads ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=java,operations%20for%20other%20virtual%20threads)). In effect, virtual threads **simulate a vast number of threads** on top of a limited number of OS threads ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=Virtual%20threads%20are%20implemented%20in,small%20number%20of%20OS%20threads)). The only real limits are **heap memory** (to hold all those thread objects and stacks) and **scheduler throughput**. The JDK documentation notes that a single JVM *“might support millions of virtual threads”* ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=Unlike%20platform%20threads%2C%20virtual%20threads,support%20millions%20of%20virtual%20threads)), which is the scale that Loom aims for.

Importantly, the JVM uses a **ForkJoinPool-based scheduler** for virtual threads ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=The%20JDK%27s%20virtual%20thread%20scheduler,equal%20to%20the%20number%20of)). By default, the scheduler’s parallelism (number of OS carrier threads) equals the number of available CPU cores ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=The%20JDK%27s%20virtual%20thread%20scheduler,equal%20to%20the%20number%20of)). It can temporarily increase the number of OS threads if many virtual threads become *pinned* (for example, if a virtual thread calls a blocking operation that the JVM cannot deschedule, like a synchronous file I/O while holding a monitor) ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=limitations%20at%20either%20the%20OS,jdk.virtualThreadScheduler.maxPoolSize)) ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=these%20blocking%20operations%20compensate%20for,jdk.virtualThreadScheduler.maxPoolSize)). However, there is an upper bound on this expansion: by default the scheduler will use at most **256 OS threads** as carriers ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=Virtual%20threads%20run%20on%20top,modified%20with%20the%20VM%20arguments)) ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=the%20default%20max%20size%20of,modified%20with%20the%20VM%20arguments)). These defaults are tunable via JVM flags: **`jdk.virtualThreadScheduler.parallelism`** sets the number of carrier threads per processor (default 1 per CPU), and **`jdk.virtualThreadScheduler.maxPoolSize`** sets the absolute maximum number of OS threads for the virtual thread scheduler ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=the%20JVM%20starts%20up%20is,modified%20with%20the%20VM%20arguments)) ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=,the%20JVM%20has%20access%20to)). For example, if you had 16 cores, by default the scheduler starts with 16 carrier threads and can grow up to 256 if needed (256 is the out-of-the-box max) ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=the%20JVM%20starts%20up%20is,modified%20with%20the%20VM%20arguments)). You can raise `maxPoolSize` if your application legitimately needs more simultaneous active threads (e.g. to tolerate more pinned virtual threads), but the need for this is rare in most I/O-heavy workloads ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=the%20JVM%20starts%20up%20is,modified%20with%20the%20VM%20arguments)). Aside from this carrier thread pool, the **virtual thread count itself has no built-in limit** – you are limited only by memory and performance considerations (e.g. garbage collection overhead for millions of thread objects).

**Summary:** Platform threads are limited by OS thread capacity and memory (with no JVM-configured numeric cap but practical limits in the thousands), whereas virtual threads have **no strict JVM-imposed limit on quantity**, enabling potentially orders of magnitude more threads (millions) ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=Unlike%20platform%20threads%2C%20virtual%20threads,support%20millions%20of%20virtual%20threads)). Platform threads each monopolize an OS thread ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=A%20platform%20thread%20is%20implemented,the%20number%20of%20OS%20threads)), but virtual threads multiplex onto a bounded pool of carriers. Key tunable parameters include `-Xss` for platform thread stack size, and `jdk.virtualThreadScheduler.parallelism`/`maxPoolSize` for virtual thread scheduling. The table below contrasts the two:

| **Aspect**                   | **Platform Threads** (OS threads)                    | **Virtual Threads** (Loom)                             |
|------------------------------|------------------------------------------------------|--------------------------------------------------------|
| Backing thread              | One dedicated OS thread per Java thread ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=A%20platform%20thread%20is%20implemented,the%20number%20of%20OS%20threads))    | Many Java threads share a few OS carrier threads ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=a%20virtual%20thread%20calls%20a,operations%20for%20other%20virtual%20threads)) |
| Memory per thread           | High (large fixed native stack, ~1MB by default) ([A primer on Java 21 virtual threads with examples | TheServerSide](https://www.theserverside.com/tip/A-primer-on-Java-21-virtual-threads-with-examples#:~:text=The%20more%20common%20constraint%20on,that%20has%20limited%20memory%20allocation)) | Low (small heap-allocated stack chunks, grows on demand) ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=Memory%20use%20and%20interaction%20with,garbage%20collection)) |
| Scheduling                  | OS kernel scheduler (preemptive time-slicing)         | JVM scheduler (ForkJoinPool work-stealing) ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=The%20JDK%27s%20virtual%20thread%20scheduler,equal%20to%20the%20number%20of)); no time-slicing beyond carrier threads ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=match%20at%20L449%20The%20scheduler,relatively%20small%20number%20of%20platform)) |
| Theoretical max threads     | Limited by OS (often a few thousand) ([A primer on Java 21 virtual threads with examples | TheServerSide](https://www.theserverside.com/tip/A-primer-on-Java-21-virtual-threads-with-examples#:~:text=The%20more%20common%20constraint%20on,that%20has%20limited%20memory%20allocation))    | Extremely high (millions if memory allows) ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=Unlike%20platform%20threads%2C%20virtual%20threads,support%20millions%20of%20virtual%20threads)) |
| Default concurrency limit   | None (until resources exhausted or OS limit hit)      | Carrier threads = #cores (up to 256 by default) ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=the%20JVM%20starts%20up%20is,modified%20with%20the%20VM%20arguments)) (virtual threads themselves unbounded) |
| Tuning knobs                | `-Xss` (stack size), OS ulimits (threads, FDs)        | `jdk.virtualThreadScheduler.parallelism` (threads per core), `...maxPoolSize` (max carriers) ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=,the%20JVM%20has%20access%20to)) |

## Tomcat with Virtual Threads: Concurrency & Constraints

When Tomcat is configured to use virtual threads (available in Tomcat 8.5.88+, 9.0.72+, 10.1.7+, and Tomcat 11 on Java 21+), the server’s request handling model changes significantly. **Each incoming request is executed in its own virtual thread** instead of using a thread from a fixed pool ([Java 21 Virtual Threads - Dude, Where’s My Lock? | by Netflix Technology Blog | Netflix TechBlog](https://netflixtechblog.com/java-21-virtual-threads-dude-wheres-my-lock-3052540e231d#:~:text=In%20our%20environment%2C%20we%20utilize,here)). In Tomcat’s configuration, this is enabled by setting `useVirtualThreads="true"` on the Connector or Executor, which causes Tomcat to use an internal **`VirtualThreadExecutor`** for task execution ([Apache Tomcat 10 Configuration Reference (10.1.39) - The HTTP Connector](https://tomcat.apache.org/tomcat-10.1-doc/config/http.html#:~:text=)). That executor simply spawns a new virtual thread for every task (HTTP connection/request) with *no upper bound* on the number of virtual threads (['Re: Virtual Threads' - MARC](https://marc.info/?l=tomcat-user&m=169394364509789#:~:text=,order)). In other words, Tomcat will not throttle or queue requests based on thread count when using virtual threads – it will create as many threads as needed to handle all concurrent requests arriving.

**How many concurrent requests can Tomcat handle with virtual threads?** In principle, far more than with the old fixed pool. The **traditional limit of 200 simultaneous threads** (Tomcat’s default `maxThreads`) no longer applies, since virtual threads aren’t limited by that pool size (['Re: Virtual Threads' - MARC](https://marc.info/?l=tomcat-user&m=169394364509789#:~:text=,order)). Instead, the limit becomes **Tomcat’s connection limit and your system resources**. Tomcat’s HTTP connector still has a `maxConnections` setting which by default is 8192 for NIO/NIO2 connectors ([Apache Tomcat 10 Configuration Reference (10.1.39) - The HTTP Connector](https://tomcat.apache.org/tomcat-10.1-doc/config/http.html#:~:text=The%20maximum%20number%20of%20connections,server%20will%20accept%2C%20but%20not)). This means out-of-the-box Tomcat will accept up to 8192 concurrent connections/requests when using virtual threads (after which additional connections are queued in the OS accept backlog) ([Apache Tomcat 10 Configuration Reference (10.1.39) - The HTTP Connector](https://tomcat.apache.org/tomcat-10.1-doc/config/http.html#:~:text=The%20maximum%20number%20of%20connections,server%20will%20accept%2C%20but%20not)). You can raise `maxConnections` (even set it to `-1` for “no limit” on some connectors) ([Apache Tomcat 10 Configuration Reference (10.1.39) - The HTTP Connector](https://tomcat.apache.org/tomcat-10.1-doc/config/http.html#:~:text=match%20at%20L526%20For%20NIO%2FNIO2,connections%20will%20not%20be%20counted)), in which case the real cap becomes your OS limits (e.g. maximum file descriptors for sockets) and memory. In practice, **tens of thousands of concurrent connections** can be handled, so long as the host machine has enough memory and the OS is tuned for that many sockets.

However, just because you *can* create a huge number of concurrent virtual threads doesn’t mean the server has infinite throughput. **Other constraints become the bottlenecks:**

- **Heap Memory Overhead:** Each virtual thread is lightweight, but not free. A thread object and a shallow stack (plus the request objects) consume heap memory. Millions of virtual threads could occupy gigabytes of heap (e.g. if each uses a few KB or tens of KB of stack and data). The JVM stores virtual thread stacks in the garbage-collected heap and can collect unused stack segments, but if you have extremely high concurrency you need a large heap to accommodate it ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=Memory%20use%20and%20interaction%20with,garbage%20collection)). You should also account for per-connection buffers and request/response objects. For example, Tomcat allocates up to 8 KB for HTTP request headers per request; 10,000 concurrent requests would consume ~80 MB just in header buffers ([Apache Tomcat 10 Configuration Reference (10.1.39) - The HTTP Connector](https://tomcat.apache.org/tomcat-10.1-doc/config/http.html#:~:text=the%20value%20of%20the%20,attribute)) ([Apache Tomcat 10 Configuration Reference (10.1.39) - The HTTP Connector](https://tomcat.apache.org/tomcat-10.1-doc/config/http.html#:~:text=If%20you%20see%20,heap%20consumed%20by%20request%20headers)). In summary, ensure the **Java heap** is sized for the peak number of concurrent requests your application may see, or you risk `OutOfMemoryError` or excessive GC from millions of live objects.

- **Native Memory & OS Limits:** Virtual threads themselves don’t each tie up native stacks, but the underlying **carrier OS threads** do have native stack memory. By default, at most 256 carrier threads will be used ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=the%20JVM%20starts%20up%20is,modified%20with%20the%20VM%20arguments)), which is on the order of a few hundred MB of native memory (256 × default 1MB stack ~256 MB). This is usually not a problem on modern servers. More important are OS limits like **file descriptors** and **network sockets** – each TCP connection to Tomcat uses a file descriptor. Linux systems often default to allowing ~1024 open files per process; this must be increased (e.g. to tens of thousands) to handle thousands of simultaneous connections. Similarly, the OS networking stack must be configured to handle large connection volumes (e.g. size of listen backlog, ephemeral port exhaustion is typically not an issue for inbound connections, etc.). In short, ensure **ulimit -n** (max open files) and other OS settings are tuned for high concurrency. The Tomcat `maxConnections` (default 8192) provides a safety limit at the application level ([Apache Tomcat 10 Configuration Reference (10.1.39) - The HTTP Connector](https://tomcat.apache.org/tomcat-10.1-doc/config/http.html#:~:text=The%20maximum%20number%20of%20connections,server%20will%20accept%2C%20but%20not)); you might tune this upward if your OS and memory can support more concurrent sockets.

- **CPU and Carrier Threads:** Virtual threads do not magically increase CPU power – they only help utilize it more efficiently. Only as many threads can *actively execute* at a time as there are carrier OS threads (by default, roughly one per processor core). If you have, say, 1000 concurrent requests that are CPU-intensive (doing heavy computation in Java), only ~N of them will run in parallel at any instant (where N = number of cores or carrier threads); the rest will be queued internally until a carrier becomes free. Unlike OS threads, the Loom scheduler **does not time-slice virtual threads preemptively** beyond the OS scheduling of carriers ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=match%20at%20L449%20The%20scheduler,relatively%20small%20number%20of%20platform)). This means if a virtual thread is running a long CPU-bound task, it won’t yield to another virtual thread until it blocks or completes. In practice, for CPU-bound workloads, **virtual threads offer little advantage** – throughput is limited by CPU, and platform threads would achieve similar throughput (the main difference is platform threads would context-switch via the OS, whereas virtual threads context-switch in the JVM when blocking). **I/O-bound workloads**, on the other hand, benefit greatly: when a virtual thread performs blocking I/O (e.g. reading from a socket or database), the JVM will park that virtual thread and free the carrier for another task ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=java,operations%20for%20other%20virtual%20threads)). Thus, Tomcat with virtual threads can have thousands of requests waiting on I/O (network or disk) without tying up thousands of OS threads. The net result is much better scalability for typical web apps that spend a lot of time waiting on databases, web services, or file I/O. The Spring team notes that with blocking I/O on virtual threads, you can **increase concurrency** significantly – provided you also have **available connections and CPU** to support the extra load ([Embracing Virtual Threads](https://spring.io/blog/2022/10/11/embracing-virtual-threads#:~:text=Higher%20concurrency%20can%20be%20achieved,Specifically%2C%20these%20are)). In other words, your **DB connection pool** or external service may become the limiting factor before the thread count does. Be prepared to expand those pools or use backpressure if necessary.

- **Application-Level Limits:** Consider what each request does. Even if the servlet container can handle (for example) 5,000 concurrent requests, your application might struggle if it, say, tries to spawn its own additional threads or uses large caches per thread. Similarly, components like JDBC connection pools, thread pools for internal tasks, etc., might need reconfiguration. For instance, if you expect 10x more concurrent requests than before, you may need to increase your database connection pool size or switch to a *pool-less* async driver (or simply accept that database throughput will bottleneck at its own limit). The Spring framework blog emphasizes three resources needed for higher concurrency: **(1) enough connections (e.g. to DB or other services), (2) sufficient memory, and (3) unused CPU time** to handle the extra threads ([Embracing Virtual Threads](https://spring.io/blog/2022/10/11/embracing-virtual-threads#:~:text=Higher%20concurrency%20can%20be%20achieved,Specifically%2C%20these%20are)). If any of those are maxed out, adding more threads (even virtual) won’t improve throughput.

In practice, Tomcat with virtual threads can handle very high loads. For example, if you have the heap and OS tuned for it, handling on the order of 5,000–10,000 simultaneous idle connections or slow requests is quite feasible on a single Tomcat instance (something that would be perilous with 5k OS threads). Throughput-wise, you might see that using virtual threads gives equal or better throughput up to the point where another resource becomes saturated. **Latency can also improve under load**, because the server no longer has to queue requests waiting for a free thread – work can begin immediately in a new virtual thread. The Tomcat team has shown that virtual threads maintain throughput better as concurrency grows beyond the number of CPU cores, compared to the platform thread pool (which would simply max out at its thread limit) ([Preparing Spring Web Applications for Loom](https://tomcat.apache.org/presentations/2023-10-07-cocna-Loom.pdf#:~:text=Virtual%20threads%20have%20higher%20throughput,show%20increased%20throughput%20compared%20to)) ([Preparing Spring Web Applications for Loom](https://tomcat.apache.org/presentations/2023-10-07-cocna-Loom.pdf#:~:text=Virtual%20threads%20%E2%80%A2%203%2C408%2C798%20requests,complete%20in%20more%20than%201200ms)).

**Important constraints to monitor:** Keep an eye on **heap usage** (many threads = many stacks and objects), **GC behavior** (a very large number of short-lived threads could affect GC, although thread stacks are just objects to the GC), **OS resource usage** (file handles, memory mappings, etc.), and **carrier thread saturation**. The latter means checking if all carrier threads are busy but many virtual threads are queued waiting for a carrier – this could indicate a problem (e.g. all carriers pinned, see below). You can use JDK Flight Recorder or `jstack`/`jcmd` to observe if virtual threads are backing up. Generally, if your application is mostly I/O-bound and well-behaved, Tomcat’s virtual thread mode will let you utilize the machine’s throughput more fully by serving a very large number of concurrent requests without the usual thread pool choke point.

## Tomcat with Platform Threads: Practical Thread Limits

In a traditional Tomcat setup (prior to Loom, or with `useVirtualThreads="false"`), Tomcat uses a **bounded thread pool** for request processing. The connector’s `maxThreads` setting (default **200**) determines the maximum number of simultaneous requests that can be actively handled ([Apache Tomcat 10 Configuration Reference (10.1.39) - The HTTP Connector](https://tomcat.apache.org/tomcat-10.1-doc/config/http.html#:~:text=The%20maximum%20number%20of%20request,that%20it%20is%20not%20used)). If all threads are busy, incoming connections are queued (up to `acceptCount`) until a thread is free. In effect, Tomcat imposes a **hard cap** (200 by default) on concurrent requests with platform threads. This can be raised – for example, some high-traffic sites might configure `maxThreads` to 300, 500, or higher. But there are diminishing returns and real limits when scaling up the thread pool:

- **Thread creation overhead:** Each additional platform thread consumes significant memory and some CPU overhead. If you increase Tomcat’s thread pool to, say, 1000 threads, you must ensure the JVM and OS can handle that. 1000 threads with a default 1MB stack each means ~1 GB of memory just for thread stacks, *outside* of the Java heap. The JVM will throw an out-of-memory error (“**unable to create new native thread**”) if you exhaust the process’s address space or hit OS limits when creating threads. Often, the OS default limit of ~1024 threads per process (for non-root users on Linux) might be encountered ([A primer on Java 21 virtual threads with examples | TheServerSide](https://www.theserverside.com/tip/A-primer-on-Java-21-virtual-threads-with-examples#:~:text=,end%20clusters)) unless raised. So while Tomcat allows you to set `maxThreads` to 1000+, the practical upper bound might be constrained by these factors. There is **no explicit maxThreads limit in Tomcat’s code** (aside from it being an `int`), but the OS and JVM memory will cap you.

- **Context switching and scheduling costs:** With very large thread counts, the OS scheduler can become a bottleneck. Having thousands of runnable threads competes for CPU, leading to more context switches and cache misses. If most threads are idle or blocked, this overhead is not as bad, but if they wake up or contend, latency can spike. In a workload where threads spend a lot of time waiting (e.g. blocked on I/O or locks), a large thread pool mostly wastes memory. That’s why in the pre-Loom era, an alternative approach for high concurrency was to use NIO with asynchronous request handling (Servlet 3.0+ async and completion handlers) to avoid needing a thread per connection.

- **Memory and GC overhead:** Beyond native stack memory, each thread has a Java `Thread` object and associated structures. Thousands of threads mean thousands of such objects, which can put pressure on the garbage collector (especially older JDKs where threads could be GC roots or had to be carefully managed after termination). Modern GCs handle lots of objects fine, but it’s a consideration if threads churn.

**Typical practical limits:** Many Tomcat deployments historically stick with a few hundred threads at most. Values like 200 (default) up to maybe 500 are common. Going into the thousands was usually only seen in special cases and often revealed issues. For instance, at around a few thousand threads, you might see the JVM failing to create new threads even if heap is sufficient, because the **process ran out of virtual memory or hit OS thread limits**. The general advice was to scale out (run more Tomcat instances behind a load balancer) or use async I/O, rather than crank up a single JVM’s thread count too high. As one report noted, *“systems cannot make an unlimited number of threads… the number of threads is constrained by CPU capacity and memory, with memory being the more common constraint”* ([A primer on Java 21 virtual threads with examples | TheServerSide](https://www.theserverside.com/tip/A-primer-on-Java-21-virtual-threads-with-examples#:~:text=Systems%20cannot%20make%20an%20unlimited,number%20of%20threads)). So, before Loom, if an application needed to handle say 10,000 concurrent mostly-waiting connections, you had to either use the async servlet API (so those connections don’t each hold a thread) or use an event-driven server. Tomcat’s pool of 200 would simply queue the rest, which could become a bottleneck or lead to timeouts.

In summary, with platform threads the **practical maximum** threads in Tomcat is usually in the low thousands (and even that requires tuning). There isn’t a single hard threshold—rather, you will notice issues (memory exhaustion or throughput collapse) if you configure far beyond what the hardware can support. The default 200 is conservative but sensible for many apps. If you needed more, you might go to a few hundred, but beyond that you were likely better off switching strategies. This is exactly the limitation that virtual threads were created to address – allowing a *thread-per-request* model to scale without hitting the wall at a few hundred threads.

## Best Practices and Caveats for Using Virtual Threads in Tomcat

Enabling virtual threads in Tomcat can yield big scalability wins, but it also requires rethinking some assumptions. Here are key **considerations, best practices, and known issues** when switching Tomcat to use virtual threads under Java 21+:

- **Use a supported Tomcat version and Java version:** Virtual threads became a final feature in JDK 21, and Tomcat’s support was added in 2023. Tomcat 10.1.7+ and 9.0.72+ (June 2023 releases) include Loom support, and Tomcat 11 (Jakarta EE 11) fully embraces it. Ensure you run Tomcat on **Java 21 or later** (earlier preview implementations of Loom on JDK 19/20 will also work with Tomcat 10.1/11 if enabled, but it’s best to use the stable JDK 21). In server.xml, set `useVirtualThreads="true"` on your HTTP Connector (or define an `<Executor useVirtualThreads="true">` for shared executors). If you don’t set this, Tomcat will continue using the old thread pool. Note that if you use an `<Executor>` element, Tomcat will ignore the connector’s `useVirtualThreads` attribute (you’d configure it on the Executor itself) ([Apache Tomcat 10 Configuration Reference (10.1.39) - The HTTP Connector](https://tomcat.apache.org/tomcat-10.1-doc/config/http.html#:~:text=,false)).

- **Don’t pool virtual threads (no thread pooling needed):** In the Loom model, a new thread is so cheap that you no longer gain anything by reusing threads or maintaining an idle pool. Tomcat’s `VirtualThreadExecutor` intentionally does not reuse threads – it creates and starts a fresh virtual thread for each task ([tomcat/java/org/apache/tomcat/util/threads/VirtualThreadExecutor.java at main · apache/tomcat · GitHub](https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/threads/VirtualThreadExecutor.java#:~:text=public%20void%20execute%28Runnable%20command%29%20)) ([tomcat/java/org/apache/tomcat/util/threads/VirtualThreadExecutor.java at main · apache/tomcat · GitHub](https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/threads/VirtualThreadExecutor.java#:~:text=threadBuilder)). This is aligned with Oracle’s guidance: *“Don’t pool virtual threads, as they are not a scarce resource.”* ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=%E2%9A%A0%EF%B8%8F%20Warning%3A%20Don%E2%80%99t%20pool%20virtual,are%20not%20a%20scarce%20resource)) Each virtual thread will terminate after completing the request. **Best practice:** remove or disable any custom thread-pooling logic that was only there to limit thread usage. Let the platform create as many virtual threads as needed. If you need to limit throughput to an external resource, do it with semaphores or limited connection pools, not by artificially bounding threads ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=When%20I%20have%20presented%20on,which%20is%20simply%20a%20counter)) ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=%E2%9A%A0%EF%B8%8F%20Warning%3A%20Don%E2%80%99t%20pool%20virtual,are%20not%20a%20scarce%20resource)). The code is simpler when you assume you can always spawn another thread.

- **Beware of *pinned* virtual threads:** A virtual thread can *pin* (block) an OS carrier thread if it performs a blocking operation that the Loom runtime cannot intercept. The two main causes are: (a) blocking while holding a monitor (`synchronized` block/method), and (b) calling a native or foreign method that doesn’t cooperate with Loom ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=There%20are%20two%20scenarios%20in,is%20pinned%20to%20its%20carrier)) ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=blocking%20operations%20because%20it%20is,pinned%20to%20its%20carrier)). If a virtual thread gets pinned in a long blocking operation, it ties up one of the limited carrier threads, reducing concurrency. Tomcat itself and the JDK libraries have been designed to avoid pinning in most common cases – e.g. the JDK’s I/O, `LockSupport`, `ReentrantLock`, `CompletableFuture.get()`, etc., are Loom-aware and will not pin carriers ([Embracing Virtual Threads](https://spring.io/blog/2022/10/11/embracing-virtual-threads#:~:text=with%20Virtual%20Threads%3A%20They%20effectively,can%20progress%20with%20its%20work)). But your **application or libraries might have synchronization that causes pinning**. A real-world example came from Netflix’s experience: they enabled virtual threads in Spring Boot + Tomcat and observed the server eventually hang with thousands of requests waiting. The thread dump showed all carrier threads were blocked, because a certain library (a tracing/metrics library using `ReentrantLock` inside a synchronized context) caused many virtual threads to block while pinned to carriers ([Java 21 Virtual Threads - Dude, Where’s My Lock? | by Netflix Technology Blog | Netflix TechBlog](https://netflixtechblog.com/java-21-virtual-threads-dude-wheres-my-lock-3052540e231d#:~:text=Tying%20this%20information%20back%20to,threads%20to%20mount%20them%20onto)) ([Java 21 Virtual Threads - Dude, Where’s My Lock? | by Netflix Technology Blog | Netflix TechBlog](https://netflixtechblog.com/java-21-virtual-threads-dude-wheres-my-lock-3052540e231d#:~:text=dump%20obtained%20from%20the%20stuck,instance)). Tomcat kept creating new virtual threads for new requests, but none could run since carriers were all busy – leading to a stall ([Java 21 Virtual Threads - Dude, Where’s My Lock? | by Netflix Technology Blog | Netflix TechBlog](https://netflixtechblog.com/java-21-virtual-threads-dude-wheres-my-lock-3052540e231d#:~:text=Tying%20this%20information%20back%20to,threads%20to%20mount%20them%20onto)). **Mitigation:** Audit your code for places where you hold locks around I/O or long waits. Prefer using `java.util.concurrent` locks (like `ReentrantLock`) over `synchronized` for locks that might be held during blocking operations ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=OS%20thread%20are%20blocked%20for,an%20application%20by%20capturing%20carriers)) – the Loom docs explicitly recommend this, as the JVM can still deschedule a virtual thread blocked on a `ReentrantLock` (it parks via LockSupport, which Loom can manage) ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=scalability,an%20application%20by%20capturing%20carriers)) ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=The%20scheduler%20does%20not%20compensate,memory%20operations.%20As)), whereas a thread inside a synchronized method that performs I/O will pin. If you do encounter pinning and can’t easily change the code, one workaround is to increase the `jdk.virtualThreadScheduler.maxPoolSize` to allow more carrier threads (so that a few pinned carriers won’t halt all progress) – but this is more of a last resort. It’s better to fix the pinning at the source if possible. The JDK provides diagnostics: you can run with `-Djdk.tracePinnedThreads=full` to log stack traces of any pinning occurrences ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=,see%20JDK%20Flight%20Recorder)). Use this in testing to catch problematic code paths.

- **Watch out for starvation across multiple web apps:** Under platform threads, Tomcat could isolate web applications by using separate executor pools per connector or per <Executor>. With virtual threads, however, **all virtual threads share the common ForkJoin scheduler** at the JVM level. This means that if you have multiple web applications in the same Tomcat instance (or multiple connectors) all using virtual threads, a flood of requests in one app can potentially starve threads for another. In classic Tomcat, if each app had its own thread pool of say 50 threads, they’d each get a fair share. In the Loom model, there is one virtual thread pool (effectively unlimited tasks) and one underlying carrier pool. The scheduling is work-stealing and not strictly FIFO (['Re: Virtual Threads' - MARC](https://marc.info/?l=tomcat-user&m=169394364509789#:~:text=The%20virtual%20thread%20scheduler%20uses,so%20it%20isn%27t%20quite%20FIFO)) ([Preparing Spring Web Applications for Loom](https://tomcat.apache.org/presentations/2023-10-07-cocna-Loom.pdf#:~:text=The%20virtual%20thread%20scheduler%20uses,work%20stealing%20queue%20by%20default)), so there is a possibility that a heavy workload from App A keeps the CPU busy, delaying tasks from App B. As Tomcat developer Mark Thomas explained, *“once virtual threads are introduced, a limitless number of requests [from one context] can be queued in front of a request to another [context], which can experience starvation”* (['Re: Virtual Threads' - MARC](https://marc.info/?l=tomcat-user&m=169394364509789#:~:text=,separate%20Executors%20for%20each%20application)). There is currently **no built-in way to assign different scheduler priorities or separate carrier pools** per application (['Re: Virtual Threads' - MARC](https://marc.info/?l=tomcat-user&m=169394364509789#:~:text=I%20think%20you%20have%20summed,would%20need%20to%20address%20this)). Best practice if this is a concern: if you have an admin or critical app that must remain responsive even under load, you might choose to **not use virtual threads for that specific connector** (i.e. keep a small dedicated platform thread pool for it), or run it on a separate Tomcat instance. In Tomcat, you can configure one connector with `useVirtualThreads="false"` (default) and others with `"true"`, or use a separate Executor for one. This way, for example, your internal management app could keep using a bounded pool so it’s not affected by a storm of virtual threads from the public API. In the future, if the Loom API allows multiple schedulers, Tomcat could be enhanced to use separate virtual thread executors per webapp, but as of Java 21 that’s not available (['Re: Virtual Threads' - MARC](https://marc.info/?l=tomcat-user&m=169394364509789#:~:text=I%20think%20you%20have%20summed,would%20need%20to%20address%20this)).

- **ThreadLocal and InheritableThreadLocal considerations:** Earlier iterations of Project Loom had an option to disable thread-locals on virtual threads for performance, but in JDK 21, **virtual threads always support thread-local variables** ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=,code%20to%20use%20virtual%20threads)). That means your MDC (Mapped Diagnostic Context) for logging, Spring Security context, or other ThreadLocal-based context should work as expected on virtual threads. However, keep in mind that because threads are not reused, any data stored in a ThreadLocal lives for only one request (which is usually what you want). Patterns that reused thread-locals across tasks (for caching expensive objects, e.g. using a threadlocal to cache a `SimpleDateFormat`) are less useful now – since each task gets a new thread, you don’t get a cache hit after the thread is gone. It may be better to use object pooling or just create new objects if they are cheap. In short, **ThreadLocal usage is fine**, but avoid designing it for reuse across tasks. Also, if you heavily use InheritableThreadLocal, note that creating millions of threads with inherited values could have a memory cost – each new virtual thread will copy the parent’s inheritable threadlocals at creation. Usually that’s negligible, but be mindful if you have large TL values.

- **Adjustment of other pools and timeouts:** Because Tomcat can now handle so many concurrent requests, you may need to adjust other configurations. For example, your **database connection pool** (e.g. HikariCP) may become the choke point – if it only allows 50 concurrent DB connections but you now have 1000 threads hitting the DB, 950 of them will block (park) waiting for a connection. This won’t crash the server (virtual threads can park without issue), but it could increase latency for those requests. You might increase the pool size or use a semaphore to limit how many requests go to a certain service at once (as shown in the Inside Java example using a Semaphore to rate-limit calls) ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=When%20I%20have%20presented%20on,which%20is%20simply%20a%20counter)) ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=public%20class%20SemaphoreExample%20,10%29%3B%20%2F%2FSet%20permit%20limit)). Similarly, **HTTP client pools** (if your app calls out to other HTTP services) might need tuning. Keep an eye on **timeout settings** as well: with more requests in flight, you might hit scenarios where timeouts need to be adjusted (for example, if you previously relied on the thread pool to implicitly limit load, now you might see more concurrent slow operations, potentially requiring a shorter timeout to fail fast, or else more work piles up).

- **Monitoring and debugging changes:** The way you monitor threads will change slightly. A normal `jstack` thread dump will by default show the carrier threads and any *currently mounted* virtual threads (those actively running or blocked in certain states), but it **might not list all dormant virtual threads** that are parked on I/O or waiting. In JDK 21, to get a complete picture, it’s recommended to use `jcmd <pid> Thread.dump_to_file` (with `-format=json` or `text`) which **includes virtual threads**, or enable the relevant JFR events ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=jcmd%20%3CPID%3E%20Thread.dump_to_file%20)). Netflix engineers discovered that their usual thread dump tools didn’t show the virtual threads, which initially made it tricky to diagnose issues ([Java 21 Virtual Threads - Dude, Where’s My Lock? | by Netflix Technology Blog | Netflix TechBlog](https://netflixtechblog.com/java-21-virtual-threads-dude-wheres-my-lock-3052540e231d#:~:text=surprised%20to%20find%20that%20all,heap%20dump%20from%20the%20instance)). Now, JDK tooling is catching up: JFR has events for virtual thread start/end and pinning, and thread dump APIs include virtual threads. **Best practice:** update your monitoring and profiling processes. Use JDK Mission Control or JFR to track virtual thread metrics. Be aware that metrics like “Tomcat busy threads” will not mean the same thing when using virtual threads – you might see a metric showing 10,000 threads but that’s not a sign of overload in the Loom world, whereas it would have been alarming before. Instead, focus on CPU utilization, queue lengths, and application-specific throughput/latency metrics.

- **Compatibility and stability:** Most libraries and frameworks have been tested with virtual threads by now, especially since Loom was in preview for a while. Spring Framework and Spring Boot, for example, have added support (Spring 6 / Boot 3 embrace virtual threads for @Async and allow Tomcat to use them). Still, it’s wise to **test your entire application under load** with virtual threads. Some known issues as of early Java 21 adoption included things like JDBC drivers using thread-local caches (should be fine) or thread pool assumptions. The good news is that using virtual threads at the Tomcat level *does not require code changes to your servlets or controllers* – the servlet API calls are all synchronous as before, so your code doesn’t “know” it’s on a virtual thread. But pay attention to any warnings on the Tomcat mailing lists or release notes. For instance, ensure you have the latest **Tomcat patch release** because early versions had a few bugs with virtual thread mode (if any were found, they would be in release notes). As of Tomcat 10.1.8/10.1.9 the support is considered solid.

- **Rethinking asynchronous APIs:** One of the reasons server frameworks introduced async request handling (Servlet 3.0’s `startAsync`, Spring WebFlux, etc.) was to avoid tying up threads during long waits. With virtual threads, that reason diminishes. It’s often simpler to use a synchronous programming model with blocking I/O, and let the JVM handle the threading. For example, you might not need to use servlet async request processing at all – each request can block on downstream calls without hurting scalability, so writing straight-line code is fine. The Spring team notes that the benefits of complex asynchronous frameworks are “invalidated” in many cases by virtual threads ([Embracing Virtual Threads](https://spring.io/blog/2022/10/11/embracing-virtual-threads#:~:text=Assumptions%20leading%20to%20the%20asynchronous,would%20be%20no%20longer%20required)). **Best practice:** consider simplifying your code to normal synchronous logic now that you can afford a thread per request. This can make your application code more readable and maintainable. (Of course, if you’re already using an async stack like WebFlux, it will still work on Loom – but the imperative style on Loom may offer similar scalability with less complexity.)

In conclusion, switching Tomcat to virtual threads in Java 21+ can greatly increase the number of concurrent requests your server can handle without running out of threads. There is **no hard JVM limit on virtual threads** (it’s mainly a question of memory and OS resources) ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=Unlike%20platform%20threads%2C%20virtual%20threads,support%20millions%20of%20virtual%20threads)), whereas platform threads were limited by OS thread capacity and typically capped in the hundreds ([A primer on Java 21 virtual threads with examples | TheServerSide](https://www.theserverside.com/tip/A-primer-on-Java-21-virtual-threads-with-examples#:~:text=The%20more%20common%20constraint%20on,that%20has%20limited%20memory%20allocation)). Real-world usage shows Tomcat can handle thousands of simultaneous connections with virtual threads, but you should **monitor memory, CPU, and other resources** to find the true bottleneck. Adopt best practices like avoiding long blocking operations under locks (to prevent pinning) and tuning connection pools to match the new level of concurrency. Also be mindful of fairness issues when mixing workloads on the same scheduler. By following these guidelines and leveraging official documentation and JDK tooling, you can safely maximize Tomcat’s throughput using Java 21’s virtual threads – achieving high scalability *“for free”* (in terms of easier programming model) while keeping your system stable and efficient.

**Sources:**

- OpenJDK JEP 444: *Virtual Threads* – details of Loom’s implementation and limits ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=The%20JDK%27s%20virtual%20thread%20scheduler,equal%20to%20the%20number%20of)) ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=these%20blocking%20operations%20compensate%20for,jdk.virtualThreadScheduler.maxPoolSize)) ([JEP 444: Virtual Threads](https://openjdk.java.net/jeps/444#:~:text=Memory%20use%20and%20interaction%20with,garbage%20collection))  
- Oracle Java 21 Concurrency Guide – *Virtual Threads* (official docs) ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=A%20platform%20thread%20is%20implemented,the%20number%20of%20OS%20threads)) ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=Unlike%20platform%20threads%2C%20virtual%20threads,support%20millions%20of%20virtual%20threads)) ([Virtual Threads](https://docs.oracle.com/en/java/javase/21/core/virtual-threads.html#:~:text=Virtual%20threads%20are%20suitable%20for,intensive%20operations))  
- Apache Tomcat 10.1 Configuration Reference – Connector thread settings (`maxThreads`, `maxConnections`, etc.) ([Apache Tomcat 10 Configuration Reference (10.1.39) - The HTTP Connector](https://tomcat.apache.org/tomcat-10.1-doc/config/http.html#:~:text=The%20maximum%20number%20of%20request,that%20it%20is%20not%20used)) ([Apache Tomcat 10 Configuration Reference (10.1.39) - The HTTP Connector](https://tomcat.apache.org/tomcat-10.1-doc/config/http.html#:~:text=The%20maximum%20number%20of%20connections,8192))  
- Apache Tomcat 10.1/11 Mailing List (Mark Thomas) – discussion of virtual thread support and implications (['Re: Virtual Threads' - MARC](https://marc.info/?l=tomcat-user&m=169394364509789#:~:text=,version%2019%20or%20later%20JVM)) (['Re: Virtual Threads' - MARC](https://marc.info/?l=tomcat-user&m=169394364509789#:~:text=,separate%20Executors%20for%20each%20application)) (['Re: Virtual Threads' - MARC](https://marc.info/?l=tomcat-user&m=169394364509789#:~:text=I%20think%20you%20have%20summed,would%20need%20to%20address%20this))  
- Inside Java (Oracle) – *Managing Throughput with Virtual Threads* (blog) ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=Virtual%20threads%20run%20on%20top,modified%20with%20the%20VM%20arguments)) ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=,the%20JVM%20has%20access%20to)) ([Managing Throughput with Virtual Threads - Sip of Java – Inside.java](https://inside.java/2024/02/04/sip094/#:~:text=%E2%9A%A0%EF%B8%8F%20Warning%3A%20Don%E2%80%99t%20pool%20virtual,are%20not%20a%20scarce%20resource))  
- Spring Blog – *Embracing Virtual Threads* – usage of Loom in Spring apps ([Embracing Virtual Threads](https://spring.io/blog/2022/10/11/embracing-virtual-threads#:~:text=Threads%20if%20they%20were%20built,Virtual%20Threads%20can%20increase%20concurrency)) ([Embracing Virtual Threads](https://spring.io/blog/2022/10/11/embracing-virtual-threads#:~:text=with%20Virtual%20Threads%3A%20They%20effectively,can%20progress%20with%20its%20work)) ([Embracing Virtual Threads](https://spring.io/blog/2022/10/11/embracing-virtual-threads#:~:text=Assumptions%20leading%20to%20the%20asynchronous,would%20be%20no%20longer%20required))  
- Netflix TechBlog – *Java 21 Virtual Threads: Dude, Where’s My Lock?* – case study of an issue with Tomcat + virtual threads ([Java 21 Virtual Threads - Dude, Where’s My Lock? | by Netflix Technology Blog | Netflix TechBlog](https://netflixtechblog.com/java-21-virtual-threads-dude-wheres-my-lock-3052540e231d#:~:text=In%20our%20environment%2C%20we%20utilize,here)) ([Java 21 Virtual Threads - Dude, Where’s My Lock? | by Netflix Technology Blog | Netflix TechBlog](https://netflixtechblog.com/java-21-virtual-threads-dude-wheres-my-lock-3052540e231d#:~:text=Tying%20this%20information%20back%20to,threads%20to%20mount%20them%20onto))  
- TheServerSide.com – *A primer on Java 21 virtual threads* – overview of thread limits and Loom benefits ([A primer on Java 21 virtual threads with examples | TheServerSide](https://www.theserverside.com/tip/A-primer-on-Java-21-virtual-threads-with-examples#:~:text=The%20more%20common%20constraint%20on,that%20has%20limited%20memory%20allocation))
